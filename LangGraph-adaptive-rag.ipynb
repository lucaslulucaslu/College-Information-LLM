{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c852d53e-68ef-4a40-9211-11dedab73de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'college-information-llm'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d71c7e-b111-4586-870d-2b7f96fe1482",
   "metadata": {},
   "source": [
    "-----------------retriever-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00b49e5-105f-4539-b0ae-36af7283f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledgebase import TXTKnowledgeBase\n",
    "SEARCH_DOCS_NUM=4\n",
    "\n",
    "kb=TXTKnowledgeBase(txt_source_folder_path='lxbd')\n",
    "vector=kb.return_retriever_from_persistant_vector_db()\n",
    "\n",
    "retriever = vector.as_retriever(search_kwargs={'k':SEARCH_DOCS_NUM})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11452d5f-3e58-4268-851c-fa5807394161",
   "metadata": {},
   "source": [
    "------------------------LLMs-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c39bd8-824e-4df8-bffc-e7a276449586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n",
      "datasource='vectorstore'\n",
      "datasource='database'\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"基于用户的查询词条选择最相关的资料来源\"\"\"\n",
    "\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\",\"database\"] = Field(\n",
    "        ...,\n",
    "        description=\"基于用户的问题选择web_search或者vectrostore或者database.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"你是一位选择路径的专家，你需要基于用户的提问选择是使用web_search, vectorstore还是database.\n",
    "vectorstore包含了关于总体的在美国留学相关的资料，比如美国大学排名，美国留学申请，美国转学等等.\n",
    "database包含了特定某一所大学的相关资料，比如这所大学的排名、录取率、学费、生活费、专业设置、犯罪率等等.\n",
    "如果用户的问题是美国留学相关但是不针对某一所大学的问题，请选择vectorstore，如果是针对某一所美国大学的问题，请选择database，尽量少选择web_search.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n",
    "\n",
    "print(\n",
    "    question_router.invoke({\"question\": \"怎么钓鱼？\"})\n",
    ")\n",
    "print(\n",
    "    question_router.invoke({\"question\": \"美国大学排名？\"})\n",
    ")\n",
    "print(\n",
    "    question_router.invoke({\"question\": \"哈佛的学费是多少？\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f4fda-5eff-4e4d-86fe-c55af80b6c65",
   "metadata": {},
   "source": [
    "-----------------------Retriever Grader-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f034f745-ed5f-488a-aa0a-abbca07acad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquestion = \"美国大学排名\"\\ndocs = retriever.invoke(question)\\ndoc_txt = docs[1].page_content\\nprint(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"检查vectorstore取回的资料相关性，是与否回答\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"检查资料与问题是否相关，回答只能是：'是'、'否'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"你是一位评判取回资料与用户问题是否相关的评判员. \\n \n",
    "    如果取回的资料包含用户问题的关键词，或者取回资料与用户问题有相关性，评判为'是'，否则评判为'否'. \\n\n",
    "    评判标准不需要太严格，主要是为了排除错误的取回资料. \\n\n",
    "    最后的回答只能是：'是'与'否'，'是'对应相关，'否'对应不相关.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"取回资料如下: \\n\\n {document} \\n\\n 用户问题如下: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\"\"\"\n",
    "question = \"美国大学排名\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44909921-5e68-42e5-aa66-d7e2fde6ab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngeneration = rag_chain.invoke({\"context\": docs, \"question\": question})\\nprint(generation)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system',\"你是一位回答问题的助手，你只能使用下面取回的资料回答问题，如果你不知道问题的答案，请回答'不知道'，取回的资料如下\\n\\n{context}\\n\\n\"),\n",
    "    ('human',\"{question}\")\n",
    "])\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test Run\n",
    "\"\"\"\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a1837f-9975-4d3a-ab1d-c1e1894e8b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"评判生成的答案是否为捏造的.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"评判回答是否真实，回答只能为'是'与'否'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"你作为一名评判员需要评判LLM生成的答案是否真实基于取回的资料. \\n \n",
    "     回答只能为'是'与'否'. '是'表示回答是基于取回资料的真实回答，这里不需要太严格，与取回资料是相关的真实回答就可以.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"取回资料如下: \\n\\n {documents} \\n\\n LLM生成答案如下: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "\"\"\"\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154da3ac-9ab8-4c52-b1e6-e98bd776e3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanswer_grader.invoke({\"question\": question, \"generation\": generation})\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"评判回答是否解决用户的问题.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"评判回答是否能解决用户的问题，回答只能为'是'与'否'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"你是一名评判员，你需要评判LLM回答是否能解决或者回答用户的问题\\n \n",
    "     回答只能为'是'与'否'，'是'表示LLM回答能解决或者回答用户的问题.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"用户问题如下: \\n\\n {question} \\n\\n LLM回答如下: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "\n",
    "\"\"\"\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366bd0d7-164a-48a5-b872-5ea9eba30365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquestion_rewriter.invoke({\"question\": question})\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"你是一名重新提问的提问员，你需要基于用户的提问，并且更好的从vectorstore取回资料来优化问题. \n",
    "你需要审视用户的提问以及抓住问题隐含的内容和意图.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"用户问题如下: \\n\\n {question} \\n 提出一个优化的问题.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "\n",
    "\"\"\"\n",
    "question_rewriter.invoke({\"question\": question})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94bec8c4-53b4-4b08-8d8f-07277d1bb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5d3c12-bd7c-4786-918e-9d51e2c54209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Graph state\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ddba9-305a-4bd3-91c4-03bc348ab16e",
   "metadata": {},
   "source": [
    "----------------Graph Flow----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2e43fd1-7e92-42de-8492-d0c488161f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"是\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "    return {\"documents\": web_results, \"question\": question}\n",
    "\n",
    "\n",
    "### Edges ###\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n",
    "    elif source.datasource==\"database\":\n",
    "        print(\"---ROUTE QUESTION TO DATABASE\")\n",
    "        return \"database\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"是\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"是\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n",
    "def database(state):\n",
    "    \"\"\"\n",
    "    Retrieve database infos\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print('database func called')\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f4266-4f77-49cd-bfbd-ad718e919301",
   "metadata": {},
   "source": [
    "------------------build graph---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52fb47e6-5ee8-401a-a3d3-e72657e58e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"web_search\", web_search)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"database\",database_fuc)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "        \"database\":\"database\"\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"database\",END)\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a80bcc3-5b45-4699-8932-9a63bad15d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'-------------------------------'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'-------------------------------'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Node 'generate':\"\n",
      "'-------------------------------'\n",
      "('根据提供的资料，美国大学排名可以从不同的角度和机构进行评定。一些影响力较大的排名机构包括《美国新闻和世界报道》（U.S. News and World '\n",
      " 'Report）、《福布斯》（Forbes）、《商业周刊》（Bloomberg Businessweek）、《华尔街日报》（Wall Street '\n",
      " 'Journal）等。这些机构根据不同的指标和权重对美国大学进行排名，如学术声誉、教师资源、学生生源质量等。\\n'\n",
      " '\\n'\n",
      " '具体的排名结果可能会有所不同，因为每个机构所侧重的指标和权重不同。如果您对特定排名的具体结果感兴趣，可以查看相应的排名榜单。')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\n",
    "    \"question\": \"美国大学排名\"\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"-------------------------------\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21c5c583-5d7d-4129-a8ac-e76dc8128c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "---ROUTE QUESTION TO DATABASE\n",
      "database func called\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"question\": \"哈佛大学排名\"\n",
    "}\n",
    "respose=app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dbc073d-182e-419c-bbd2-6d8b0e9aed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'美国大学排名是根据不同的排名机构和标准而定的。一些影响力较大的排名机构包括《美国新闻和世界报道》（U.S. News and World Report）、《福布斯》（Forbes）、《商业周刊》（Bloomberg Businessweek）、《华尔街日报》（Wall Street Journal）等。它们每年都会发布不同的排名榜单，涵盖综合性排名、研究生院排名、商学院排名等。\\n\\n具体到2023年的排名数据，根据《美国新闻和世界报道》（U.S. News and World Report）的排名，TOP10的美国大学包括：\\n1. 普林斯顿大学\\n2. 麻省理工学院\\n3. 哈佛大学\\n4. 斯坦福大学\\n5. 耶鲁大学\\n6. 芝加哥大学\\n7. 约翰霍普金斯大学\\n8. 宾夕法尼亚大学\\n9. 加州理工学院\\n10. 杜克大学 和 西北大学（并列）\\n\\n另外，《福布斯》（Forbes）也有自己的美国最佳大学排名，2022年的排名前几名包括：\\n1. 麻省理工学院\\n2. 斯坦福大学\\n3. 加州大学伯克利分校\\n4. 普林斯顿大学\\n5. 哥伦比亚大学\\n6. 加州大学洛杉矶分校\\n7. 威廉姆斯学院\\n8. 耶鲁大学\\n9. 杜克大学\\n10. 宾夕法尼亚大学\\n\\n这些排名都是根据不同的指标和权重来评定的，学生在选择美国大学时可以参考这些排名数据，但也要根据自己的需求和兴趣做出选择。'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respose['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f159e1-88a9-40c1-86cd-39b359cc6c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
